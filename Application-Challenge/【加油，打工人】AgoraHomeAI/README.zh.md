## 项目目标
基于目前声网产品方向的RTC实时音视频、RTM实时通信（信令和即时通信）以及智能硬件方向，本项目拟利用声网提供的技术以及机器学习技术，在智慧城市、智能家居等方面做些应用实现。
1. 利用音视频实时传输实现家庭、户外视频监控并实时传输到AI中心
2. 利用RTM信令，给智能硬件设备发送控制指令
3. 利用开源Yolo V3结合Unity 3D实现AI中心实时目标检测

## 预期成果
系统比较庞大，完全实现的话会包含两种情况：
#### 小规模
以智能家居为主题，实现房屋内的Web摄像头、网络摄像头、智能硬件（旧手机、树莓派+Agora）视频传输和AI识别，以及实时信令对硬件进行控制；实现远程对房屋内的事件监控、应急控制等内容。
#### 大规模
以云计算集群形式，提供基于云服务的AI服务中心，支持各类视频数据的实时训练、识别、结果输出；支持用户自定义识别数据集、选择算法、自主选择事件报警以及配置事件响应。

## 项目过程
#### 硬件配置
1. 硬件中控：原计划采用Android things（奈何性能太差）。后来找了个努比亚旧手机，作为智能硬件中控，并实现视频采集
2. 智能硬件：Node MCU单片机，实现对智能小车远程控制
3. 控制中心：PC主机，I7 9700K 显卡 GTX1050ti；内存16G；固态硬盘500G
#### 软件配置
1. 使用声网安卓版RTM和RTC，Unity 3D版RTM和RTC实现音视频传输和信令交互
2. 采用Yolo V3的C++版本算法，配合使用Opencv进行图像处理
3. 利用C++封装技术，实现在Unity 3D中对Yolo 算法的调用和通信，支持Web摄像头，Agora视频，Http视频流（暂不支持RTSP和RTMP）
#### 开发工具
系统包含PC端运行程序和Android端运行程序
1. Android Studio 4（安卓程序开发）
2. Unity 3D 2019.3.2（PC程序开发）
3. Visual Studio 2015（C++插件制作）
#### 开发过程
1. 进行声网音视频和云信令接入，通过Node MCU智能硬件，实现安卓端利用局域网控制小车的移动和摄像头旋转
2. 进行C++插件功能开发，在完成Yolo配置后，将其封装成DLL供C#和Unity 3D调用
3. 利用声网的Unity 3D插件包和其他插件包，实现视频文件、视频流、声网视频数据的实时识别
## 实际效果
目前实现点对点的远程视频、群组云信令和智能设备控制；
视频AI的实时识别和数据输出；
支持Agora、视频文件、网络视频（http）实时识别；
演示效果图见【同级目录/一些截图】
